{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "f8efca9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.mobilenet import MobileNet, preprocess_input\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "5d3f5c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model for transfer learning\n",
    "Model = MobileNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "962d6da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the directories containing the Eurosat datasets\n",
    "data_dirs = {\n",
    "    90: r\"D:\\MCA 3rd SEM\\Small Industrial Project\\DATASET_COMPARE\\90\",\n",
    "    80: r\"D:\\MCA 3rd SEM\\Small Industrial Project\\DATASET_COMPARE\\80\",\n",
    "    70: r\"D:\\MCA 3rd SEM\\Small Industrial Project\\DATASET_COMPARE\\70\",\n",
    "    60: r\"D:\\MCA 3rd SEM\\Small Industrial Project\\DATASET_COMPARE\\60\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "06849f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the input shape for the model\n",
    "input_shape = (128, 128, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "3bf4fa9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use ReduceLROnPlateau callback\n",
    "lr_reduction = ReduceLROnPlateau(monitor='val_loss', \n",
    "                                 patience=3, \n",
    "                                 verbose=1, \n",
    "                                 factor=0.5, \n",
    "                                 min_lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "0c160af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an image data generator with more augmentations and validation split\n",
    "datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,  # use preprocess_input from inception_v3\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    validation_split=0.2  # add this line for validation split\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "9997d7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a dictionary to store the accuracy of each model at each stage\n",
    "accuracy = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "f35a6f6f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for stage 90\n",
      "Found 720 images belonging to 10 classes.\n",
      "Found 180 images belonging to 10 classes.\n",
      "Epoch 1/10\n",
      "23/23 [==============================] - 60s 2s/step - loss: 3.0875 - accuracy: 0.5417 - val_loss: 12.2619 - val_accuracy: 0.2167 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "23/23 [==============================] - 50s 2s/step - loss: 1.3865 - accuracy: 0.7819 - val_loss: 11.2087 - val_accuracy: 0.3722 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "23/23 [==============================] - 47s 2s/step - loss: 1.7912 - accuracy: 0.7667 - val_loss: 12.9786 - val_accuracy: 0.4222 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "23/23 [==============================] - 47s 2s/step - loss: 1.1039 - accuracy: 0.8361 - val_loss: 8.6662 - val_accuracy: 0.4667 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "23/23 [==============================] - 48s 2s/step - loss: 0.8237 - accuracy: 0.8736 - val_loss: 8.9264 - val_accuracy: 0.4389 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "23/23 [==============================] - 47s 2s/step - loss: 0.8593 - accuracy: 0.8542 - val_loss: 6.0206 - val_accuracy: 0.5833 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "23/23 [==============================] - 48s 2s/step - loss: 0.7406 - accuracy: 0.8806 - val_loss: 7.7132 - val_accuracy: 0.5056 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "23/23 [==============================] - 46s 2s/step - loss: 0.6944 - accuracy: 0.8667 - val_loss: 4.0540 - val_accuracy: 0.6556 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "23/23 [==============================] - 48s 2s/step - loss: 0.5331 - accuracy: 0.8944 - val_loss: 3.9882 - val_accuracy: 0.6833 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "23/23 [==============================] - 47s 2s/step - loss: 0.4689 - accuracy: 0.9125 - val_loss: 2.6126 - val_accuracy: 0.7389 - lr: 0.0010\n",
      "Training for stage 80\n",
      "Found 640 images belonging to 10 classes.\n",
      "Found 160 images belonging to 10 classes.\n",
      "Epoch 1/10\n",
      "20/20 [==============================] - 49s 2s/step - loss: 2.5880 - accuracy: 0.5813 - val_loss: 14.3685 - val_accuracy: 0.2062 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "20/20 [==============================] - 41s 2s/step - loss: 2.0965 - accuracy: 0.7625 - val_loss: 16.9343 - val_accuracy: 0.2125 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "20/20 [==============================] - 41s 2s/step - loss: 1.5041 - accuracy: 0.8156 - val_loss: 14.2598 - val_accuracy: 0.3375 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "20/20 [==============================] - 42s 2s/step - loss: 1.3454 - accuracy: 0.8531 - val_loss: 9.9906 - val_accuracy: 0.4750 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "20/20 [==============================] - 42s 2s/step - loss: 1.1650 - accuracy: 0.8594 - val_loss: 9.7466 - val_accuracy: 0.5125 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "20/20 [==============================] - 41s 2s/step - loss: 0.9699 - accuracy: 0.8625 - val_loss: 4.6474 - val_accuracy: 0.6125 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "20/20 [==============================] - 42s 2s/step - loss: 1.0174 - accuracy: 0.8672 - val_loss: 8.7380 - val_accuracy: 0.5750 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "20/20 [==============================] - 42s 2s/step - loss: 0.7991 - accuracy: 0.8984 - val_loss: 4.2266 - val_accuracy: 0.7188 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "20/20 [==============================] - 42s 2s/step - loss: 0.7465 - accuracy: 0.8859 - val_loss: 11.2284 - val_accuracy: 0.6438 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "20/20 [==============================] - 42s 2s/step - loss: 0.8689 - accuracy: 0.8750 - val_loss: 8.2421 - val_accuracy: 0.6375 - lr: 0.0010\n",
      "Training for stage 70\n",
      "Found 560 images belonging to 10 classes.\n",
      "Found 140 images belonging to 10 classes.\n",
      "Epoch 1/10\n",
      "18/18 [==============================] - 42s 2s/step - loss: 3.3344 - accuracy: 0.4821 - val_loss: 14.1098 - val_accuracy: 0.3071 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "18/18 [==============================] - 35s 2s/step - loss: 1.3157 - accuracy: 0.7964 - val_loss: 10.4512 - val_accuracy: 0.2714 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "18/18 [==============================] - 36s 2s/step - loss: 1.6660 - accuracy: 0.7786 - val_loss: 15.5798 - val_accuracy: 0.3571 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "18/18 [==============================] - 36s 2s/step - loss: 1.3323 - accuracy: 0.8357 - val_loss: 13.3364 - val_accuracy: 0.3714 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "18/18 [==============================] - ETA: 0s - loss: 1.0352 - accuracy: 0.8179\n",
      "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "18/18 [==============================] - 37s 2s/step - loss: 1.0352 - accuracy: 0.8179 - val_loss: 12.0972 - val_accuracy: 0.4643 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "18/18 [==============================] - 37s 2s/step - loss: 0.7835 - accuracy: 0.8732 - val_loss: 8.4612 - val_accuracy: 0.5500 - lr: 5.0000e-04\n",
      "Epoch 7/10\n",
      "18/18 [==============================] - 37s 2s/step - loss: 0.5616 - accuracy: 0.9000 - val_loss: 2.9871 - val_accuracy: 0.6571 - lr: 5.0000e-04\n",
      "Epoch 8/10\n",
      "18/18 [==============================] - 37s 2s/step - loss: 0.5102 - accuracy: 0.9196 - val_loss: 3.4648 - val_accuracy: 0.7714 - lr: 5.0000e-04\n",
      "Epoch 9/10\n",
      "18/18 [==============================] - 36s 2s/step - loss: 0.3327 - accuracy: 0.9321 - val_loss: 1.7630 - val_accuracy: 0.8000 - lr: 5.0000e-04\n",
      "Epoch 10/10\n",
      "18/18 [==============================] - 36s 2s/step - loss: 0.3688 - accuracy: 0.9232 - val_loss: 1.1323 - val_accuracy: 0.8643 - lr: 5.0000e-04\n",
      "Training for stage 60\n",
      "Found 480 images belonging to 10 classes.\n",
      "Found 120 images belonging to 10 classes.\n",
      "Epoch 1/10\n",
      "15/15 [==============================] - 37s 2s/step - loss: 3.4611 - accuracy: 0.4708 - val_loss: 11.3811 - val_accuracy: 0.2083 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "15/15 [==============================] - 30s 2s/step - loss: 1.6767 - accuracy: 0.7292 - val_loss: 14.9022 - val_accuracy: 0.2333 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "15/15 [==============================] - 30s 2s/step - loss: 1.4956 - accuracy: 0.7854 - val_loss: 14.6373 - val_accuracy: 0.4000 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "15/15 [==============================] - 30s 2s/step - loss: 1.1568 - accuracy: 0.8271 - val_loss: 10.5001 - val_accuracy: 0.4083 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "15/15 [==============================] - 30s 2s/step - loss: 1.3752 - accuracy: 0.8313 - val_loss: 8.6522 - val_accuracy: 0.4833 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "15/15 [==============================] - 30s 2s/step - loss: 1.2088 - accuracy: 0.8396 - val_loss: 10.0333 - val_accuracy: 0.5667 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "15/15 [==============================] - 30s 2s/step - loss: 0.9101 - accuracy: 0.8687 - val_loss: 5.7334 - val_accuracy: 0.6000 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "15/15 [==============================] - 30s 2s/step - loss: 0.9434 - accuracy: 0.8646 - val_loss: 12.1869 - val_accuracy: 0.5333 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "15/15 [==============================] - 30s 2s/step - loss: 0.7510 - accuracy: 0.8917 - val_loss: 8.2755 - val_accuracy: 0.4833 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "15/15 [==============================] - ETA: 0s - loss: 1.1453 - accuracy: 0.8875\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "15/15 [==============================] - 30s 2s/step - loss: 1.1453 - accuracy: 0.8875 - val_loss: 12.2309 - val_accuracy: 0.5583 - lr: 0.0010\n",
      "Accuracy for each stage: {90: 0.7388888597488403, 80: 0.637499988079071, 70: 0.8642857074737549, 60: 0.5583333373069763}\n"
     ]
    }
   ],
   "source": [
    "# Loop over each dataset directory for training\n",
    "for stage, data_dir in data_dirs.items():\n",
    "    print(f\"Training for stage {stage}\")\n",
    "    \n",
    "    # Create a train generator with only `stage` images per class\n",
    "    train_generator = datagen.flow_from_directory(\n",
    "        data_dir, \n",
    "        target_size=(128,128), \n",
    "        batch_size=32, \n",
    "        subset='training'  # specify this as 'training'\n",
    "    )\n",
    "\n",
    "    # Create a validation generator\n",
    "    validation_generator = datagen.flow_from_directory(\n",
    "        data_dir, \n",
    "        target_size=(128,128), \n",
    "        batch_size=32, \n",
    "        subset='validation'  # specify this as 'validation'\n",
    "    )\n",
    "\n",
    "    # Create a new instance of the model for transfer learning\n",
    "    base_model = Model(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    model = Sequential()\n",
    "    model.add(base_model)\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(0.5)) # Add dropout layer to reduce overfitting\n",
    "\n",
    "    # The number of classes is automatically inferred from the subdirectories\n",
    "    model.add(Dense(train_generator.num_classes, activation='softmax'))\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Train the model with validation data and callbacks\n",
    "    history = model.fit(\n",
    "        train_generator, \n",
    "        epochs=10, \n",
    "        validation_data=validation_generator,  # use validation_data instead of validation_split\n",
    "        callbacks=[lr_reduction]\n",
    "    )\n",
    "\n",
    "    # Store the accuracy of the model at this stage\n",
    "    accuracy[stage] = history.history['val_accuracy'][-1]\n",
    "\n",
    "print(\"Accuracy for each stage:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "255087a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for each stage: {90: 0.7388888597488403, 80: 0.637499988079071, 70: 0.8642857074737549, 60: 0.5583333373069763}\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# After training the model and storing the accuracy\n",
    "print(\"Accuracy for each stage:\", accuracy)\n",
    "\n",
    "# Create a list of stages and their corresponding accuracies\n",
    "stages = list(accuracy.keys())\n",
    "accuracies = list(accuracy.values())\n",
    "\n",
    "# Create a bar plot\n",
    "plt.bar(stages, accuracies)\n",
    "plt.xlabel('Stage')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy for each stage')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "ffcbc86e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 193ms/step\n",
      "The predicted class is: River\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.resnet50 import preprocess_input\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "\n",
    "# Define the path to your image for testing\n",
    "# img_path = r\"D:\\MCA 3rd SEM\\Small Industrial Project\\DATASET_COMPARE\\90\\AnnualCrop\\AnnualCrop_1.jpg\"\n",
    "# img_path = r'D:\\MCA 3rd SEM\\Small Industrial Project\\DATASET_COMPARE\\90\\HerbaceousVegetation\\HerbaceousVegetation_7.jpg'\n",
    "img_path = r\"D:\\MCA 3rd SEM\\Small Industrial Project\\DATASET_COMPARE\\90\\River\\River_90.jpg\"\n",
    "# img_path = r\"D:\\MCA 3rd SEM\\Small Industrial Project\\DATASET_COMPARE\\90\\SeaLake\\SeaLake_1.jpg\"\n",
    "\n",
    "# Load and preprocess the image\n",
    "img = load_img(img_path, target_size=input_shape[:2])\n",
    "x = img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)\n",
    "\n",
    "# Use the trained model to make a prediction\n",
    "preds = model.predict(x)\n",
    "\n",
    "# Get the class labels from the train generator\n",
    "classes = list(train_generator.class_indices.keys())\n",
    "\n",
    "# Decode the prediction\n",
    "predicted_class = np.argmax(preds[0])\n",
    "\n",
    "print(f'The predicted class is: {classes[predicted_class]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "fc43f2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to your directory for testing\n",
    "dir_path = r\"D:\\MCA 3rd SEM\\Small Industrial Project\\TEST\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "58ea8cdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 96ms/step\n",
      "The predicted class for AnnualCrop_1.jpg is: River\n",
      "1/1 [==============================] - 0s 97ms/step\n",
      "The predicted class for Forest_1.jpg is: SeaLake\n",
      "1/1 [==============================] - 0s 98ms/step\n",
      "The predicted class for HerbaceousVegetation_1.jpg is: River\n",
      "1/1 [==============================] - 0s 96ms/step\n",
      "The predicted class for Highway_1.jpg is: Highway\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "The predicted class for Industrial_1.jpg is: Industrial\n",
      "1/1 [==============================] - 0s 93ms/step\n",
      "The predicted class for Pasture_1.jpg is: River\n",
      "1/1 [==============================] - 0s 97ms/step\n",
      "The predicted class for PermanentCrop_1.jpg is: Industrial\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "The predicted class for Residential_1.jpg is: River\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "The predicted class for River_1.jpg is: River\n",
      "1/1 [==============================] - 0s 92ms/step\n",
      "The predicted class for SeaLake_1.jpg is: SeaLake\n"
     ]
    }
   ],
   "source": [
    "# Get a list of all image files in the directory\n",
    "img_files = [f for f in os.listdir(dir_path) if f.endswith('.jpg')]\n",
    "\n",
    "# Loop over each image file\n",
    "for img_file in img_files:\n",
    "    # Load and preprocess the image\n",
    "    img = load_img(os.path.join(dir_path, img_file), target_size=input_shape[:2])\n",
    "    x = img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "\n",
    "    # Use the trained model to make a prediction\n",
    "    preds = model.predict(x)\n",
    "\n",
    "    # Decode the prediction\n",
    "    predicted_class = np.argmax(preds[0])\n",
    "\n",
    "    print(f'The predicted class for {img_file} is: {classes[predicted_class]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758bc656",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
